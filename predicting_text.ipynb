{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbf0860",
   "metadata": {},
   "source": [
    "# Build RNN to generate hunger games sounding text\n",
    "\n",
    "based on tutorial in here : https://www.tensorflow.org/text/tutorials/text_generation\n",
    "\n",
    "Could not use all features since I have tf version 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62ae9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f17ceac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a268cd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"(1) The Hunger Games.txt\", 'rb') as file : \n",
    "    txt_file = file.readlines()\n",
    "type(txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aaad785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a89f0dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_all = [str(x)[2:] for x in txt_file][1:]\n",
    "txt_all_long = [x.replace('\\\\r','\\\\s').replace('\\\\n','\\\\s') \n",
    "                for x in txt_all if len(x) > 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f44ce6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_text = ' '.join(txt_all_long)\n",
    "vocab = sorted(set(single_text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f8bae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size, out_size = 200, 100\n",
    "def split_input_sequence(seq) : \n",
    "    \"\"\"\n",
    "    split sequence into all but last & all but first\n",
    "    \"\"\"\n",
    "    input_text = seq[:-1]\n",
    "    output_text = seq[1:]\n",
    "    return input_text, output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4acb2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_split = tf.strings.unicode_split(single_text, input_encoding='UTF-8')\n",
    "data = tf.data.Dataset.from_tensor_slices(uc_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbf31270",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_lookup = {str(x):i for i,x in enumerate(list(vocab))}\n",
    "letter_lookup = {i:str(x) for i,x in enumerate(list(vocab))}\n",
    "uc_np = pd.Series(uc_split.numpy().astype(str)).astype(str).replace(vocab_lookup).values\n",
    "tens = tf.convert_to_tensor(uc_np, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d632ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c57adf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "I\n",
      " \n",
      "w\n",
      "a\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "def translate(n) : \n",
    "    \"\"\"\n",
    "    translate\n",
    "    \"\"\"\n",
    "    return letter_lookup[n]\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(translate(ids.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24b053d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[44 55 52 61  0 30  0 70 48 58 52  0 68 63  5  0 67 55 52  0 62 67 55 52\n",
      " 65  0 66 56 51 52  0 62 53  0 67 55 52  0 49 52 51  0 56 66  0 50 62 59\n",
      " 51  7  0 34 72  0 53 56 61 54 52 65 66  0 66 67 65 52 67 50 55  0 62 68\n",
      " 67  5  0 66 52 52 58 56 61 54  0 37 65 56 60 66  0 70 48 65 60 67 55  0\n",
      " 49 68 67  0 53], shape=(101,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for seq in sequences.take(1) : \n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a101a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : [44 55 52 61  0 30  0 70 48 58 52  0 68 63  5  0 67 55 52  0 62 67 55 52\n",
      " 65  0 66 56 51 52  0 62 53  0 67 55 52  0 49 52 51  0 56 66  0 50 62 59\n",
      " 51  7  0 34 72  0 53 56 61 54 52 65 66  0 66 67 65 52 67 50 55  0 62 68\n",
      " 67  5  0 66 52 52 58 56 61 54  0 37 65 56 60 66  0 70 48 65 60 67 55  0\n",
      " 49 68 67  0]\n",
      "Target: [55 52 61  0 30  0 70 48 58 52  0 68 63  5  0 67 55 52  0 62 67 55 52 65\n",
      "  0 66 56 51 52  0 62 53  0 67 55 52  0 49 52 51  0 56 66  0 50 62 59 51\n",
      "  7  0 34 72  0 53 56 61 54 52 65 66  0 66 67 65 52 67 50 55  0 62 68 67\n",
      "  5  0 66 52 52 58 56 61 54  0 37 65 56 60 66  0 70 48 65 60 67 55  0 49\n",
      " 68 67  0 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 13:29:39.019665: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-05 13:29:39.021647: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_sequence)\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", (input_example).numpy())\n",
    "    print(\"Target:\", (target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e65f2a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "59537692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 128\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 256\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "82fd70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a1e0bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 74) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a65ca6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      multiple                  9472      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  multiple                  296448    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  19018     \n",
      "=================================================================\n",
      "Total params: 324,938\n",
      "Trainable params: 324,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f1cd2",
   "metadata": {},
   "source": [
    "### Untrained model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6c8c4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 10,  9, 14, 32, 64, 17, 24, 23, 27, 26, 69, 42, 60, 15, 35, 47,\n",
       "       11, 51,  6, 45, 39,  8, 35, 35,  7, 20,  6, 47,  2,  3, 68, 55, 13,\n",
       "       70, 41, 48, 63, 53, 24, 24, 52, 32, 58, 13, 29,  9, 50,  0, 14, 46,\n",
       "       57,  5,  8, 45,  8, 36, 24, 17, 55, 49, 49, 61, 12, 61, 58, 64, 49,\n",
       "       19, 57, 12, 50, 29, 51, 15, 41, 65, 26, 55, 25, 13, 24, 48, 55, 18,\n",
       "       39, 32, 50,  0, 17, 51, 70, 43, 11, 38, 50,  1, 28, 41, 45])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "83eca787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_array(arr) : \n",
    "    \"\"\"\n",
    "    translate over & over on an array\n",
    "    \"\"\"\n",
    "    return np.array([translate(a) for a in arr])\n",
    "def translate_array_join(arr) : \n",
    "    \"\"\"\n",
    "    join the text\n",
    "    \"\"\"\n",
    "    return ''.join(translate_array(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0ab1d610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "  The boy took one look back to the bakery as if checking that the coast was clear, then, his attenti\n",
      "\n",
      "Next Char Predictions:\n",
      " G105Kq8CBFEvUm6N\\2d-XR/NN.;-\\\"'uh4wTapfCCeKk4H0c 5Yj,/X/OC8hbbn3nkqb:j3cHd6TrEhD4Cah9RKc 8dwV2Qc!GTX\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", translate_array_join(input_example_batch[0].numpy()))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", translate_array_join(sampled_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7e863",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0556d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 15:17:20.132125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 15:17:20.474852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 15:17:20.664091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 7s 60ms/step - loss: 1.5609\n",
      "Epoch 2/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.5534\n",
      "Epoch 3/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.5464\n",
      "Epoch 4/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.5276\n",
      "Epoch 5/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.5099\n",
      "Epoch 6/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.4969\n",
      "Epoch 7/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.4875\n",
      "Epoch 8/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.4738\n",
      "Epoch 9/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.4648\n",
      "Epoch 10/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.4534\n",
      "Epoch 11/55\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 1.4434\n",
      "Epoch 12/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.4311\n",
      "Epoch 13/55\n",
      "80/80 [==============================] - 6s 66ms/step - loss: 1.4221\n",
      "Epoch 14/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.4136\n",
      "Epoch 15/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.4062\n",
      "Epoch 16/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3976\n",
      "Epoch 17/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3899\n",
      "Epoch 18/55\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.3850\n",
      "Epoch 19/55\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.3766\n",
      "Epoch 20/55\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.3723\n",
      "Epoch 21/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3657\n",
      "Epoch 22/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3591\n",
      "Epoch 23/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3545\n",
      "Epoch 24/55\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.3492\n",
      "Epoch 25/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3450\n",
      "Epoch 26/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3407\n",
      "Epoch 27/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3359\n",
      "Epoch 28/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3316\n",
      "Epoch 29/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3232\n",
      "Epoch 30/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3201\n",
      "Epoch 31/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3160\n",
      "Epoch 32/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3102\n",
      "Epoch 33/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3087\n",
      "Epoch 34/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3034\n",
      "Epoch 35/55\n",
      "80/80 [==============================] - 5s 61ms/step - loss: 1.3005\n",
      "Epoch 36/55\n",
      "80/80 [==============================] - 6s 65ms/step - loss: 1.2959\n",
      "Epoch 37/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.2928\n",
      "Epoch 38/55\n",
      "80/80 [==============================] - 6s 65ms/step - loss: 1.2897\n",
      "Epoch 39/55\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 1.2869\n",
      "Epoch 40/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.2802\n",
      "Epoch 41/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.2778\n",
      "Epoch 42/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.2726\n",
      "Epoch 43/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.2703\n",
      "Epoch 44/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.2662\n",
      "Epoch 45/55\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.2621\n",
      "Epoch 46/55\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.2589\n",
      "Epoch 47/55\n",
      "80/80 [==============================] - 6s 67ms/step - loss: 1.2551\n",
      "Epoch 48/55\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.2543\n",
      "Epoch 49/55\n",
      "80/80 [==============================] - 6s 65ms/step - loss: 1.2506\n",
      "Epoch 50/55\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.2472\n",
      "Epoch 51/55\n",
      "80/80 [==============================] - 6s 65ms/step - loss: 1.2456\n",
      "Epoch 52/55\n",
      "80/80 [==============================] - 6s 67ms/step - loss: 1.2415\n",
      "Epoch 53/55\n",
      "25/80 [========>.....................] - ETA: 3s - loss: 1.2258"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "EPOCHS = 55\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499da8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = model(inputs=tf.convert_to_tensor([[0,2,1]*30,[1,2]*45],dtype=tf.int64),states=None,return_state=True)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_array_join(tf.squeeze(tf.random.categorical(x[:, -1, :], num_samples=1), axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30241f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_tens(split) : \n",
    "    \"\"\"\n",
    "    take unicode split array & turn to tensor\n",
    "    \"\"\"\n",
    "    uc_np = pd.DataFrame(split.numpy().astype(str)).astype(str).replace(vocab_lookup).values\n",
    "    tens = tf.convert_to_tensor(uc_np, dtype=tf.int64)\n",
    "    return tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['Good morning puppy dog'])\n",
    "result = [next_char]\n",
    "for i in range(1000) : \n",
    "    nextchar = tf.strings.unicode_split(next_char, 'UTF-8')\n",
    "    ids = split_to_tens(nextchar)\n",
    "    logits, states = model(inputs=ids, states=states,return_state=True)\n",
    "    predicted_logits = logits[:, -1, :]\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1).numpy()\n",
    "    next_char = translate_array_join(predicted_ids)\n",
    "    result.append(next_char)\n",
    "results = tf.strings.join(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "14b7a0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daedc5a",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd94754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
